# Machine Learning Paper Review

<br/>

## Introduction

<br/>

As a novice researcher in the field of artificial intelligence, I find it important not only to read papers quickly and understand them well to gain insight, but also to implement them in code and review their performance.

In this repository, I will share my code implementations and reviews of various papers in the field of machine learning. My hope is that this repository will be a useful resource for other researchers who want to learn more about the latest developments in the field and implement them in code.

My primary focus is on papers related to computer vision and recommendation systems, but I may expand to other areas in the future. If you have any suggestions or requests for papers to review, please feel free to let me know.

Thank you for visiting my repository and I hope you find it useful.

<br/>

> I regret you to inform that this GitHub repository is primarily operated for my own AI study, so the some comments in code and paper review posts on my tech blog are written in Korean.

<br/>

<br/>

## Papers Review

<br/>

>  The code below is typically based on `.ipynb` files.

<br/>

### Computer Vision

<br/>

#### Radiance Field

| Name                                     | Paper Review                                                 | Code                                                         | Code Reference |
| ---------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------- |
| [NeRF](https://arxiv.org/abs/2003.08934) | [Link](https://glanceyes.tistory.com/entry/NeRF-2D-이미지를-3D-이미지로-Reconstruction하여-Novel-View-Synthesis이-가능한-Neural-Radiance-Fields) | [File](https://github.com/Glanceyes/ML-Paper-Review/blob/main/ComputerVision/NeRF.ipynb) |                |

<br/>

#### Generative Model

| Name                                         | Paper Review                                                 | Code | Code Reference |
| -------------------------------------------- | ------------------------------------------------------------ | ---- | -------------- |
| [StyleGAN](https://arxiv.org/abs/1812.04948) | [Link](https://glanceyes.tistory.com/entry/StyleGAN-Style-transfer와-mapping-network를-사용하여-disentanglement를-향상시킨-generative-Model) |      |                |
| [HoloGAN](https://arxiv.org/abs/1904.01326)  | [Link](https://glanceyes.tistory.com/entry/HoloGAN-Natural-이미지로부터-3D-representation에-관해-unsupervised-learning-할-수-있는-모델) |      |                |

<br/>

#### Renderer

| Name                                          | Paper Review                                                 | Code | Code Reference |
| --------------------------------------------- | ------------------------------------------------------------ | ---- | -------------- |
| [RenderNet](https://arxiv.org/abs/1806.06575) | [Link](https://glanceyes.tistory.com/entry/RenderNet-3D-shape를-가지고-differentiable-rendering을-수행할-수-있는-Convolutional-network) |      |                |

<br/>

<br/>

### Recommendation System



#### Autoencoder

| Name                                     | Paper Review                                                 | Code | Code Reference |
| ---------------------------------------- | ------------------------------------------------------------ | ---- | -------------- |
| [EASE](https://arxiv.org/abs/1905.03375) | [Link](https://glanceyes.tistory.com/entry/Embarrassingly-Shallow-Autoencoders-for-Sparse-Data-모델이-희소-데이터에-강한-이유) |      |                |

<br/>

<br/>

## Acknowledgments

<br/>

The code and the review in this repository is based on the original implementation by the authors of each paper. We thank them for releasing their code.

<br/>

<br/>

## License

<br/>

This project is licensed under the MIT License - see the [LICENSE](https://chat.openai.com/chat/LICENSE) file for details. Some kinds of codes for paper's implementation are protected under the licenses specified by the authors. In such cases, the source of the code is left together.
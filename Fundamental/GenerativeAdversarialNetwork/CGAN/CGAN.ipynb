{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6DeGxWFWbFhD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import easydict\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xwOqdZWDhTec"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vkzv9Wn-hn6X"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
        "    batch_size=4, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M-HEaXzCiXBH"
      },
      "outputs": [],
      "source": [
        "# Initialize weights of network\n",
        "def normal_init(m, mean, std):\n",
        "  # network m이 fully connected layer이면\n",
        "  if isinstance(m, nn.Linear):\n",
        "    m.weight.data.normal_(mean, std)\n",
        "    m.bias.data.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zd1FL49Xi5nj"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    # z value를 100차원에서 256차원으로 임베딩한다.\n",
        "    self.fc1_1 = nn.Linear(100, 256)\n",
        "    self.fc1_1_bn = nn.BatchNorm1d(256)\n",
        "\n",
        "    # y value(class label)가 10차원이고 이를 256차원으로 임베딩한다.\n",
        "    self.fc1_2 = nn.Linear(10, 256)\n",
        "    self.fc1_2_bn = nn.BatchNorm1d(256)\n",
        "\n",
        "    # 임베딩한 z와 y를 concatenation 하면 512차원\n",
        "    self.fc2 = nn.Linear(512, 2048)\n",
        "    self.fc2_bn = nn.BatchNorm1d(2048)\n",
        "\n",
        "    self.fc3 = nn.Linear(2048, 1024)\n",
        "    self.fc3_bn = nn.BatchNorm1d(1024)\n",
        "\n",
        "    # 이미지 크기 28 * 28의 784 차원의 output 생성\n",
        "    self.fc4 = nn.Linear(1024, 784)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "  \n",
        "  def weight_init(self, mean, std):\n",
        "    for m in self._modules:\n",
        "      normal_init(self._modules[m], mean, std)\n",
        "\n",
        "  def forward(self, input, label):\n",
        "    x = F.relu(self.fc1_1_bn(self.fc1_1(input)))\n",
        "    y = F.relu(self.fc1_2_bn(self.fc1_2(label)))\n",
        "    \n",
        "    x = torch.cat([x, y], dim=1)\n",
        "\n",
        "    x = F.relu(self.fc2_bn(self.fc2(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc3_bn(self.fc3(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = F.tanh(self.fc4(x))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gbtsycbromrV"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    # generator가 생성한 784차원의 이미지 데이터를 1024차원으로 임베딩한다.\n",
        "    self.fc1_1 = nn.Linear(784, 1024)\n",
        "    # y value가 10차원이고 이를 1024차원으로 임베딩한다.\n",
        "    self.fc1_2 = nn.Linear(10, 1024)\n",
        "    \n",
        "    self.fc2 = nn.Linear(2048, 512)\n",
        "    self.fc2_bn = nn.BatchNorm1d(512)\n",
        "\n",
        "    self.fc3 = nn.Linear(512, 256)\n",
        "    self.fc3_bn = nn.BatchNorm1d(256)\n",
        "\n",
        "    self.fc4 = nn.Linear(256, 1)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "    for m in self._modules:\n",
        "      normal_init(self._modules[m], mean, std)\n",
        "\n",
        "  def forward(self, input, label):\n",
        "    x = F.leaky_relu(self.fc1_1(input), 0.1)\n",
        "    y = F.leaky_relu(self.fc1_2(label), 0.1)\n",
        "\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = F.leaky_relu(self.fc2_bn(self.fc2(x)), 0.1)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3_bn(self.fc3(x)), 0.1)\n",
        "    x = F.sigmoid(self.fc4(x))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "53o9nOhZtUSn"
      },
      "outputs": [],
      "source": [
        "parser = easydict.EasyDict({\n",
        "    \"n_epochs\": 50, \n",
        "    \"batch_size\":64, \n",
        "    \"lr\":0.00001, \n",
        "    \"b1\":0.5, \n",
        "    \"b2\":0.999, \n",
        "    \"n_cpu\":8, \n",
        "    \"latent_dim\":100, \n",
        "    \"n_classes\":10, \n",
        "    \"img_size\":28, \n",
        "    \"channels\":1, \n",
        "    \"sample_interval\":1\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hQ3NbACjtcwD"
      },
      "outputs": [],
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "img_shape = (parser.channels, parser.img_size, parser.img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4cpqnvNrtoDf"
      },
      "outputs": [],
      "source": [
        "def sample_image(n_row, epoch):\n",
        "  size = parser['img_size']\n",
        "\n",
        "  # latent space에서 뽑는 latent value z는 noise 역할\n",
        "  z = torch.randn(n_row, parser.latent_dim).type(torch.FloatTensor).cuda()\n",
        "  \n",
        "  gen_labels = []\n",
        "\n",
        "  # noise에 관해 임의로 label 생성\n",
        "  for randpos in np.random.randint(0, parser.n_classes, n_row):\n",
        "    gen_labels.append(torch.eye(parser.n_classes)[randpos])\n",
        "\n",
        "  # shape of gen_labels: (n_row, 10)\n",
        "  gen_labels = torch.stack(gen_labels).cuda()\n",
        "\n",
        "  generator.eval()\n",
        "  gen_imgs = generator(z, gen_labels)\n",
        "  save_image(gen_imgs.view(n_row, 1, size, size).data, \"%d.png\" % epoch, nrow=n_row, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "x6SMK1GewNz4"
      },
      "outputs": [],
      "source": [
        "cross_entropy = torch.nn.BCELoss().cuda()\n",
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
        "    batch_size=parser['batch_size'], shuffle=True   \n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, download=True, transform=transform),\n",
        "    batch_size=parser['batch_size'], shuffle=True\n",
        ")\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.00001, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxAGJNHzx0m5",
        "outputId": "4f4b7b67-af7d-47b7-b461-117ab4629e5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: [0/50]  Step: [0/938]   G loss: 0.70223  D loss: 0.70925  \n",
            "Train Epoch: [0/50]  Step: [100/938] G loss: 0.70903  D loss: 0.69175  \n",
            "Train Epoch: [0/50]  Step: [200/938] G loss: 0.71599  D loss: 0.68960  \n",
            "Train Epoch: [0/50]  Step: [300/938] G loss: 0.72896  D loss: 0.66992  \n",
            "Train Epoch: [0/50]  Step: [400/938] G loss: 0.74036  D loss: 0.66657  \n",
            "Train Epoch: [0/50]  Step: [500/938] G loss: 0.75312  D loss: 0.64150  \n",
            "Train Epoch: [0/50]  Step: [600/938] G loss: 0.76056  D loss: 0.63693  \n",
            "Train Epoch: [0/50]  Step: [700/938] G loss: 0.78457  D loss: 0.62080  \n",
            "Train Epoch: [0/50]  Step: [800/938] G loss: 0.79767  D loss: 0.60652  \n",
            "Train Epoch: [0/50]  Step: [900/938] G loss: 0.81074  D loss: 0.60507  \n",
            "Train Epoch: [1/50]  Step: [0/938]   G loss: 0.83261  D loss: 0.58429  \n",
            "Train Epoch: [1/50]  Step: [100/938] G loss: 0.78922  D loss: 0.61770  \n",
            "Train Epoch: [1/50]  Step: [200/938] G loss: 0.81139  D loss: 0.61687  \n",
            "Train Epoch: [1/50]  Step: [300/938] G loss: 0.80839  D loss: 0.61309  \n",
            "Train Epoch: [1/50]  Step: [400/938] G loss: 0.83510  D loss: 0.59692  \n",
            "Train Epoch: [1/50]  Step: [500/938] G loss: 0.85490  D loss: 0.57909  \n",
            "Train Epoch: [1/50]  Step: [600/938] G loss: 0.82721  D loss: 0.57310  \n",
            "Train Epoch: [1/50]  Step: [700/938] G loss: 0.89239  D loss: 0.54941  \n",
            "Train Epoch: [1/50]  Step: [800/938] G loss: 0.97650  D loss: 0.50010  \n",
            "Train Epoch: [1/50]  Step: [900/938] G loss: 0.97475  D loss: 0.48734  \n",
            "Train Epoch: [2/50]  Step: [0/938]   G loss: 0.99563  D loss: 0.47822  \n",
            "Train Epoch: [2/50]  Step: [100/938] G loss: 1.03625  D loss: 0.44583  \n",
            "Train Epoch: [2/50]  Step: [200/938] G loss: 1.07085  D loss: 0.43748  \n",
            "Train Epoch: [2/50]  Step: [300/938] G loss: 1.08645  D loss: 0.41068  \n",
            "Train Epoch: [2/50]  Step: [400/938] G loss: 1.10003  D loss: 0.38860  \n",
            "Train Epoch: [2/50]  Step: [500/938] G loss: 1.17292  D loss: 0.40260  \n",
            "Train Epoch: [2/50]  Step: [600/938] G loss: 1.11470  D loss: 0.40937  \n",
            "Train Epoch: [2/50]  Step: [700/938] G loss: 1.22010  D loss: 0.35104  \n",
            "Train Epoch: [2/50]  Step: [800/938] G loss: 1.30885  D loss: 0.35162  \n",
            "Train Epoch: [2/50]  Step: [900/938] G loss: 1.31096  D loss: 0.36981  \n",
            "Train Epoch: [3/50]  Step: [0/938]   G loss: 1.32453  D loss: 0.34509  \n",
            "Train Epoch: [3/50]  Step: [100/938] G loss: 1.32427  D loss: 0.32012  \n",
            "Train Epoch: [3/50]  Step: [200/938] G loss: 1.34251  D loss: 0.31130  \n",
            "Train Epoch: [3/50]  Step: [300/938] G loss: 1.36358  D loss: 0.29467  \n",
            "Train Epoch: [3/50]  Step: [400/938] G loss: 1.42590  D loss: 0.27750  \n",
            "Train Epoch: [3/50]  Step: [500/938] G loss: 1.46261  D loss: 0.27903  \n",
            "Train Epoch: [3/50]  Step: [600/938] G loss: 1.49149  D loss: 0.25019  \n",
            "Train Epoch: [3/50]  Step: [700/938] G loss: 1.48491  D loss: 0.23756  \n",
            "Train Epoch: [3/50]  Step: [800/938] G loss: 1.56353  D loss: 0.26254  \n",
            "Train Epoch: [3/50]  Step: [900/938] G loss: 1.55766  D loss: 0.23962  \n",
            "Train Epoch: [4/50]  Step: [0/938]   G loss: 1.45108  D loss: 0.25654  \n",
            "Train Epoch: [4/50]  Step: [100/938] G loss: 1.62611  D loss: 0.21705  \n",
            "Train Epoch: [4/50]  Step: [200/938] G loss: 1.65044  D loss: 0.25401  \n",
            "Train Epoch: [4/50]  Step: [300/938] G loss: 1.66116  D loss: 0.19717  \n",
            "Train Epoch: [4/50]  Step: [400/938] G loss: 1.71002  D loss: 0.21402  \n",
            "Train Epoch: [4/50]  Step: [500/938] G loss: 1.62951  D loss: 0.19501  \n",
            "Train Epoch: [4/50]  Step: [600/938] G loss: 1.71920  D loss: 0.21849  \n",
            "Train Epoch: [4/50]  Step: [700/938] G loss: 1.72154  D loss: 0.19165  \n",
            "Train Epoch: [4/50]  Step: [800/938] G loss: 1.73431  D loss: 0.18562  \n",
            "Train Epoch: [4/50]  Step: [900/938] G loss: 1.84349  D loss: 0.17940  \n",
            "Train Epoch: [5/50]  Step: [0/938]   G loss: 1.86057  D loss: 0.19556  \n",
            "Train Epoch: [5/50]  Step: [100/938] G loss: 1.86905  D loss: 0.16371  \n",
            "Train Epoch: [5/50]  Step: [200/938] G loss: 1.88500  D loss: 0.15438  \n",
            "Train Epoch: [5/50]  Step: [300/938] G loss: 1.91101  D loss: 0.16922  \n",
            "Train Epoch: [5/50]  Step: [400/938] G loss: 1.89249  D loss: 0.14644  \n",
            "Train Epoch: [5/50]  Step: [500/938] G loss: 1.95044  D loss: 0.15377  \n",
            "Train Epoch: [5/50]  Step: [600/938] G loss: 1.93588  D loss: 0.14834  \n",
            "Train Epoch: [5/50]  Step: [700/938] G loss: 1.91105  D loss: 0.15960  \n",
            "Train Epoch: [5/50]  Step: [800/938] G loss: 2.01085  D loss: 0.14454  \n",
            "Train Epoch: [5/50]  Step: [900/938] G loss: 2.10139  D loss: 0.14678  \n",
            "Train Epoch: [6/50]  Step: [0/938]   G loss: 2.02189  D loss: 0.12276  \n",
            "Train Epoch: [6/50]  Step: [100/938] G loss: 1.98283  D loss: 0.13907  \n",
            "Train Epoch: [6/50]  Step: [200/938] G loss: 2.19838  D loss: 0.10735  \n",
            "Train Epoch: [6/50]  Step: [300/938] G loss: 2.12717  D loss: 0.12910  \n",
            "Train Epoch: [6/50]  Step: [400/938] G loss: 2.15416  D loss: 0.12974  \n",
            "Train Epoch: [6/50]  Step: [500/938] G loss: 2.05757  D loss: 0.13251  \n",
            "Train Epoch: [6/50]  Step: [600/938] G loss: 2.18672  D loss: 0.10800  \n",
            "Train Epoch: [6/50]  Step: [700/938] G loss: 2.11689  D loss: 0.13219  \n",
            "Train Epoch: [6/50]  Step: [800/938] G loss: 2.19716  D loss: 0.13076  \n",
            "Train Epoch: [6/50]  Step: [900/938] G loss: 2.33878  D loss: 0.11127  \n",
            "Train Epoch: [7/50]  Step: [0/938]   G loss: 2.22162  D loss: 0.10503  \n",
            "Train Epoch: [7/50]  Step: [100/938] G loss: 2.34042  D loss: 0.11324  \n",
            "Train Epoch: [7/50]  Step: [200/938] G loss: 2.30824  D loss: 0.09764  \n",
            "Train Epoch: [7/50]  Step: [300/938] G loss: 2.34009  D loss: 0.10162  \n",
            "Train Epoch: [7/50]  Step: [400/938] G loss: 2.42693  D loss: 0.09802  \n",
            "Train Epoch: [7/50]  Step: [500/938] G loss: 2.08134  D loss: 0.13294  \n",
            "Train Epoch: [7/50]  Step: [600/938] G loss: 2.41844  D loss: 0.09223  \n",
            "Train Epoch: [7/50]  Step: [700/938] G loss: 2.32958  D loss: 0.09510  \n",
            "Train Epoch: [7/50]  Step: [800/938] G loss: 2.49422  D loss: 0.08081  \n",
            "Train Epoch: [7/50]  Step: [900/938] G loss: 2.44448  D loss: 0.08000  \n",
            "Train Epoch: [8/50]  Step: [0/938]   G loss: 2.18431  D loss: 0.09341  \n",
            "Train Epoch: [8/50]  Step: [100/938] G loss: 2.34348  D loss: 0.10592  \n",
            "Train Epoch: [8/50]  Step: [200/938] G loss: 2.55360  D loss: 0.10606  \n",
            "Train Epoch: [8/50]  Step: [300/938] G loss: 2.37106  D loss: 0.11216  \n",
            "Train Epoch: [8/50]  Step: [400/938] G loss: 2.58144  D loss: 0.08442  \n",
            "Train Epoch: [8/50]  Step: [500/938] G loss: 2.62119  D loss: 0.08943  \n",
            "Train Epoch: [8/50]  Step: [600/938] G loss: 2.52543  D loss: 0.09514  \n",
            "Train Epoch: [8/50]  Step: [700/938] G loss: 2.36520  D loss: 0.09480  \n",
            "Train Epoch: [8/50]  Step: [800/938] G loss: 2.54742  D loss: 0.08252  \n",
            "Train Epoch: [8/50]  Step: [900/938] G loss: 2.64180  D loss: 0.06609  \n",
            "Train Epoch: [9/50]  Step: [0/938]   G loss: 2.67515  D loss: 0.08629  \n",
            "Train Epoch: [9/50]  Step: [100/938] G loss: 2.50841  D loss: 0.07646  \n",
            "Train Epoch: [9/50]  Step: [200/938] G loss: 2.53951  D loss: 0.06876  \n",
            "Train Epoch: [9/50]  Step: [300/938] G loss: 2.77849  D loss: 0.06287  \n",
            "Train Epoch: [9/50]  Step: [400/938] G loss: 2.56234  D loss: 0.12396  \n",
            "Train Epoch: [9/50]  Step: [500/938] G loss: 2.70526  D loss: 0.06218  \n",
            "Train Epoch: [9/50]  Step: [600/938] G loss: 2.78561  D loss: 0.07221  \n",
            "Train Epoch: [9/50]  Step: [700/938] G loss: 2.61379  D loss: 0.08382  \n",
            "Train Epoch: [9/50]  Step: [800/938] G loss: 2.76474  D loss: 0.06463  \n",
            "Train Epoch: [9/50]  Step: [900/938] G loss: 2.86759  D loss: 0.10087  \n",
            "Train Epoch: [10/50] Step: [0/938]   G loss: 2.79726  D loss: 0.07122  \n",
            "Train Epoch: [10/50] Step: [100/938] G loss: 2.72499  D loss: 0.07230  \n",
            "Train Epoch: [10/50] Step: [200/938] G loss: 2.82105  D loss: 0.06283  \n",
            "Train Epoch: [10/50] Step: [300/938] G loss: 2.89805  D loss: 0.07101  \n",
            "Train Epoch: [10/50] Step: [400/938] G loss: 2.96579  D loss: 0.08518  \n",
            "Train Epoch: [10/50] Step: [500/938] G loss: 2.88149  D loss: 0.07045  \n",
            "Train Epoch: [10/50] Step: [600/938] G loss: 2.68719  D loss: 0.07478  \n",
            "Train Epoch: [10/50] Step: [700/938] G loss: 2.73924  D loss: 0.07274  \n",
            "Train Epoch: [10/50] Step: [800/938] G loss: 2.94229  D loss: 0.05861  \n",
            "Train Epoch: [10/50] Step: [900/938] G loss: 2.76843  D loss: 0.08133  \n",
            "Train Epoch: [11/50] Step: [0/938]   G loss: 2.90935  D loss: 0.12148  \n",
            "Train Epoch: [11/50] Step: [100/938] G loss: 2.89688  D loss: 0.08411  \n",
            "Train Epoch: [11/50] Step: [200/938] G loss: 3.10470  D loss: 0.06820  \n",
            "Train Epoch: [11/50] Step: [300/938] G loss: 2.95722  D loss: 0.06691  \n",
            "Train Epoch: [11/50] Step: [400/938] G loss: 2.94053  D loss: 0.05927  \n",
            "Train Epoch: [11/50] Step: [500/938] G loss: 2.94835  D loss: 0.05191  \n",
            "Train Epoch: [11/50] Step: [600/938] G loss: 2.79943  D loss: 0.06487  \n",
            "Train Epoch: [11/50] Step: [700/938] G loss: 3.10983  D loss: 0.04496  \n",
            "Train Epoch: [11/50] Step: [800/938] G loss: 3.26850  D loss: 0.04065  \n",
            "Train Epoch: [11/50] Step: [900/938] G loss: 3.16375  D loss: 0.04527  \n",
            "Train Epoch: [12/50] Step: [0/938]   G loss: 3.25159  D loss: 0.04298  \n",
            "Train Epoch: [12/50] Step: [100/938] G loss: 3.25256  D loss: 0.03601  \n",
            "Train Epoch: [12/50] Step: [200/938] G loss: 3.12638  D loss: 0.06143  \n",
            "Train Epoch: [12/50] Step: [300/938] G loss: 3.13729  D loss: 0.03571  \n",
            "Train Epoch: [12/50] Step: [400/938] G loss: 3.28970  D loss: 0.04497  \n",
            "Train Epoch: [12/50] Step: [500/938] G loss: 3.27509  D loss: 0.04433  \n",
            "Train Epoch: [12/50] Step: [600/938] G loss: 3.37170  D loss: 0.03463  \n",
            "Train Epoch: [12/50] Step: [700/938] G loss: 3.38202  D loss: 0.03208  \n",
            "Train Epoch: [12/50] Step: [800/938] G loss: 3.41589  D loss: 0.02622  \n",
            "Train Epoch: [12/50] Step: [900/938] G loss: 3.28579  D loss: 0.04085  \n",
            "Train Epoch: [13/50] Step: [0/938]   G loss: 3.32621  D loss: 0.03334  \n",
            "Train Epoch: [13/50] Step: [100/938] G loss: 3.38917  D loss: 0.03543  \n",
            "Train Epoch: [13/50] Step: [200/938] G loss: 3.16610  D loss: 0.03560  \n",
            "Train Epoch: [13/50] Step: [300/938] G loss: 3.42014  D loss: 0.03954  \n",
            "Train Epoch: [13/50] Step: [400/938] G loss: 3.38843  D loss: 0.03361  \n",
            "Train Epoch: [13/50] Step: [500/938] G loss: 3.40453  D loss: 0.03188  \n",
            "Train Epoch: [13/50] Step: [600/938] G loss: 3.49341  D loss: 0.03714  \n",
            "Train Epoch: [13/50] Step: [700/938] G loss: 3.30238  D loss: 0.03780  \n",
            "Train Epoch: [13/50] Step: [800/938] G loss: 3.55807  D loss: 0.03708  \n",
            "Train Epoch: [13/50] Step: [900/938] G loss: 3.53760  D loss: 0.04002  \n",
            "Train Epoch: [14/50] Step: [0/938]   G loss: 3.55747  D loss: 0.02896  \n",
            "Train Epoch: [14/50] Step: [100/938] G loss: 3.54563  D loss: 0.03855  \n",
            "Train Epoch: [14/50] Step: [200/938] G loss: 3.54493  D loss: 0.02467  \n",
            "Train Epoch: [14/50] Step: [300/938] G loss: 3.42595  D loss: 0.02636  \n",
            "Train Epoch: [14/50] Step: [400/938] G loss: 3.58576  D loss: 0.02485  \n",
            "Train Epoch: [14/50] Step: [500/938] G loss: 3.72115  D loss: 0.02106  \n",
            "Train Epoch: [14/50] Step: [600/938] G loss: 3.67307  D loss: 0.02159  \n",
            "Train Epoch: [14/50] Step: [700/938] G loss: 3.07796  D loss: 0.04059  \n",
            "Train Epoch: [14/50] Step: [800/938] G loss: 3.57085  D loss: 0.04991  \n",
            "Train Epoch: [14/50] Step: [900/938] G loss: 3.46295  D loss: 0.03374  \n",
            "Train Epoch: [15/50] Step: [0/938]   G loss: 3.36193  D loss: 0.02561  \n",
            "Train Epoch: [15/50] Step: [100/938] G loss: 3.59047  D loss: 0.03306  \n",
            "Train Epoch: [15/50] Step: [200/938] G loss: 3.76808  D loss: 0.02898  \n",
            "Train Epoch: [15/50] Step: [300/938] G loss: 3.69096  D loss: 0.02680  \n",
            "Train Epoch: [15/50] Step: [400/938] G loss: 3.86639  D loss: 0.02474  \n",
            "Train Epoch: [15/50] Step: [500/938] G loss: 3.58228  D loss: 0.02505  \n",
            "Train Epoch: [15/50] Step: [600/938] G loss: 3.87287  D loss: 0.03281  \n",
            "Train Epoch: [15/50] Step: [700/938] G loss: 3.59855  D loss: 0.02438  \n",
            "Train Epoch: [15/50] Step: [800/938] G loss: 3.82833  D loss: 0.02835  \n",
            "Train Epoch: [15/50] Step: [900/938] G loss: 3.76298  D loss: 0.08358  \n",
            "Train Epoch: [16/50] Step: [0/938]   G loss: 3.62562  D loss: 0.03209  \n",
            "Train Epoch: [16/50] Step: [100/938] G loss: 3.74652  D loss: 0.02909  \n",
            "Train Epoch: [16/50] Step: [200/938] G loss: 3.78650  D loss: 0.01935  \n",
            "Train Epoch: [16/50] Step: [300/938] G loss: 3.66469  D loss: 0.02682  \n",
            "Train Epoch: [16/50] Step: [400/938] G loss: 3.79698  D loss: 0.02264  \n",
            "Train Epoch: [16/50] Step: [500/938] G loss: 3.95477  D loss: 0.01836  \n",
            "Train Epoch: [16/50] Step: [600/938] G loss: 3.75081  D loss: 0.03459  \n",
            "Train Epoch: [16/50] Step: [700/938] G loss: 4.00851  D loss: 0.01542  \n",
            "Train Epoch: [16/50] Step: [800/938] G loss: 4.04158  D loss: 0.01532  \n",
            "Train Epoch: [16/50] Step: [900/938] G loss: 3.96377  D loss: 0.01798  \n",
            "Train Epoch: [17/50] Step: [0/938]   G loss: 4.00341  D loss: 0.02660  \n",
            "Train Epoch: [17/50] Step: [100/938] G loss: 4.03275  D loss: 0.03059  \n",
            "Train Epoch: [17/50] Step: [200/938] G loss: 3.91787  D loss: 0.01779  \n",
            "Train Epoch: [17/50] Step: [300/938] G loss: 4.05280  D loss: 0.01391  \n",
            "Train Epoch: [17/50] Step: [400/938] G loss: 3.92020  D loss: 0.01671  \n",
            "Train Epoch: [17/50] Step: [500/938] G loss: 4.05433  D loss: 0.01859  \n",
            "Train Epoch: [17/50] Step: [600/938] G loss: 3.91942  D loss: 0.02501  \n",
            "Train Epoch: [17/50] Step: [700/938] G loss: 3.72282  D loss: 0.01856  \n",
            "Train Epoch: [17/50] Step: [800/938] G loss: 3.99087  D loss: 0.01834  \n",
            "Train Epoch: [17/50] Step: [900/938] G loss: 4.07579  D loss: 0.02071  \n",
            "Train Epoch: [18/50] Step: [0/938]   G loss: 4.23508  D loss: 0.01552  \n",
            "Train Epoch: [18/50] Step: [100/938] G loss: 3.92263  D loss: 0.01758  \n",
            "Train Epoch: [18/50] Step: [200/938] G loss: 4.16005  D loss: 0.03280  \n",
            "Train Epoch: [18/50] Step: [300/938] G loss: 4.15773  D loss: 0.01392  \n",
            "Train Epoch: [18/50] Step: [400/938] G loss: 3.94997  D loss: 0.02237  \n",
            "Train Epoch: [18/50] Step: [500/938] G loss: 4.19089  D loss: 0.01544  \n",
            "Train Epoch: [18/50] Step: [600/938] G loss: 4.23982  D loss: 0.01212  \n",
            "Train Epoch: [18/50] Step: [700/938] G loss: 3.93736  D loss: 0.01592  \n",
            "Train Epoch: [18/50] Step: [800/938] G loss: 4.21534  D loss: 0.01976  \n",
            "Train Epoch: [18/50] Step: [900/938] G loss: 4.15434  D loss: 0.01516  \n",
            "Train Epoch: [19/50] Step: [0/938]   G loss: 4.27304  D loss: 0.02263  \n",
            "Train Epoch: [19/50] Step: [100/938] G loss: 4.24933  D loss: 0.01385  \n",
            "Train Epoch: [19/50] Step: [200/938] G loss: 4.01870  D loss: 0.01517  \n",
            "Train Epoch: [19/50] Step: [300/938] G loss: 4.11264  D loss: 0.01238  \n",
            "Train Epoch: [19/50] Step: [400/938] G loss: 4.36436  D loss: 0.01863  \n",
            "Train Epoch: [19/50] Step: [500/938] G loss: 4.37837  D loss: 0.01329  \n",
            "Train Epoch: [19/50] Step: [600/938] G loss: 4.23265  D loss: 0.01854  \n",
            "Train Epoch: [19/50] Step: [700/938] G loss: 4.26694  D loss: 0.01411  \n",
            "Train Epoch: [19/50] Step: [800/938] G loss: 4.22795  D loss: 0.02377  \n",
            "Train Epoch: [19/50] Step: [900/938] G loss: 4.32040  D loss: 0.01127  \n",
            "Train Epoch: [20/50] Step: [0/938]   G loss: 4.30493  D loss: 0.01280  \n",
            "Train Epoch: [20/50] Step: [100/938] G loss: 4.52628  D loss: 0.01129  \n",
            "Train Epoch: [20/50] Step: [200/938] G loss: 4.43369  D loss: 0.01034  \n",
            "Train Epoch: [20/50] Step: [300/938] G loss: 4.51786  D loss: 0.01045  \n",
            "Train Epoch: [20/50] Step: [400/938] G loss: 4.54779  D loss: 0.00945  \n",
            "Train Epoch: [20/50] Step: [500/938] G loss: 4.49611  D loss: 0.01454  \n",
            "Train Epoch: [20/50] Step: [600/938] G loss: 4.15269  D loss: 0.01647  \n",
            "Train Epoch: [20/50] Step: [700/938] G loss: 4.66010  D loss: 0.01215  \n",
            "Train Epoch: [20/50] Step: [800/938] G loss: 4.73112  D loss: 0.01045  \n",
            "Train Epoch: [20/50] Step: [900/938] G loss: 4.55895  D loss: 0.01120  \n",
            "Train Epoch: [21/50] Step: [0/938]   G loss: 4.43125  D loss: 0.00878  \n",
            "Train Epoch: [21/50] Step: [100/938] G loss: 4.50447  D loss: 0.01100  \n",
            "Train Epoch: [21/50] Step: [200/938] G loss: 4.66376  D loss: 0.00843  \n",
            "Train Epoch: [21/50] Step: [300/938] G loss: 4.32606  D loss: 0.01085  \n",
            "Train Epoch: [21/50] Step: [400/938] G loss: 4.75475  D loss: 0.00703  \n",
            "Train Epoch: [21/50] Step: [500/938] G loss: 4.75687  D loss: 0.00812  \n",
            "Train Epoch: [21/50] Step: [600/938] G loss: 4.68351  D loss: 0.00841  \n",
            "Train Epoch: [21/50] Step: [700/938] G loss: 4.82528  D loss: 0.02640  \n",
            "Train Epoch: [21/50] Step: [800/938] G loss: 4.78667  D loss: 0.00851  \n",
            "Train Epoch: [21/50] Step: [900/938] G loss: 4.49366  D loss: 0.01180  \n",
            "Train Epoch: [22/50] Step: [0/938]   G loss: 4.72105  D loss: 0.00766  \n",
            "Train Epoch: [22/50] Step: [100/938] G loss: 4.52668  D loss: 0.00913  \n",
            "Train Epoch: [22/50] Step: [200/938] G loss: 4.14357  D loss: 0.02084  \n",
            "Train Epoch: [22/50] Step: [300/938] G loss: 4.64013  D loss: 0.00952  \n",
            "Train Epoch: [22/50] Step: [400/938] G loss: 4.77216  D loss: 0.00765  \n",
            "Train Epoch: [22/50] Step: [500/938] G loss: 4.50062  D loss: 0.00890  \n",
            "Train Epoch: [22/50] Step: [600/938] G loss: 4.42947  D loss: 0.01070  \n",
            "Train Epoch: [22/50] Step: [700/938] G loss: 4.67894  D loss: 0.00797  \n",
            "Train Epoch: [22/50] Step: [800/938] G loss: 4.75692  D loss: 0.00886  \n",
            "Train Epoch: [22/50] Step: [900/938] G loss: 4.64883  D loss: 0.00990  \n",
            "Train Epoch: [23/50] Step: [0/938]   G loss: 4.66614  D loss: 0.00862  \n",
            "Train Epoch: [23/50] Step: [100/938] G loss: 4.69654  D loss: 0.00861  \n",
            "Train Epoch: [23/50] Step: [200/938] G loss: 4.79034  D loss: 0.01830  \n",
            "Train Epoch: [23/50] Step: [300/938] G loss: 4.53325  D loss: 0.01171  \n",
            "Train Epoch: [23/50] Step: [400/938] G loss: 4.52428  D loss: 0.00991  \n",
            "Train Epoch: [23/50] Step: [500/938] G loss: 4.80407  D loss: 0.00794  \n",
            "Train Epoch: [23/50] Step: [600/938] G loss: 4.63530  D loss: 0.01108  \n",
            "Train Epoch: [23/50] Step: [700/938] G loss: 5.05900  D loss: 0.00847  \n",
            "Train Epoch: [23/50] Step: [800/938] G loss: 4.90061  D loss: 0.00606  \n",
            "Train Epoch: [23/50] Step: [900/938] G loss: 4.67880  D loss: 0.00903  \n",
            "Train Epoch: [24/50] Step: [0/938]   G loss: 4.61859  D loss: 0.00897  \n",
            "Train Epoch: [24/50] Step: [100/938] G loss: 4.52318  D loss: 0.00798  \n",
            "Train Epoch: [24/50] Step: [200/938] G loss: 4.90324  D loss: 0.00830  \n",
            "Train Epoch: [24/50] Step: [300/938] G loss: 4.50992  D loss: 0.00935  \n",
            "Train Epoch: [24/50] Step: [400/938] G loss: 4.97514  D loss: 0.00601  \n",
            "Train Epoch: [24/50] Step: [500/938] G loss: 4.81658  D loss: 0.00908  \n",
            "Train Epoch: [24/50] Step: [600/938] G loss: 4.78828  D loss: 0.00797  \n",
            "Train Epoch: [24/50] Step: [700/938] G loss: 5.14698  D loss: 0.00576  \n",
            "Train Epoch: [24/50] Step: [800/938] G loss: 5.05942  D loss: 0.00792  \n",
            "Train Epoch: [24/50] Step: [900/938] G loss: 5.08274  D loss: 0.00519  \n",
            "Train Epoch: [25/50] Step: [0/938]   G loss: 5.08897  D loss: 0.00575  \n",
            "Train Epoch: [25/50] Step: [100/938] G loss: 5.22940  D loss: 0.00906  \n",
            "Train Epoch: [25/50] Step: [200/938] G loss: 4.92715  D loss: 0.01015  \n",
            "Train Epoch: [25/50] Step: [300/938] G loss: 5.02492  D loss: 0.03405  \n",
            "Train Epoch: [25/50] Step: [400/938] G loss: 5.09440  D loss: 0.00881  \n",
            "Train Epoch: [25/50] Step: [500/938] G loss: 4.94434  D loss: 0.00616  \n",
            "Train Epoch: [25/50] Step: [600/938] G loss: 5.20355  D loss: 0.00601  \n",
            "Train Epoch: [25/50] Step: [700/938] G loss: 5.11920  D loss: 0.00499  \n",
            "Train Epoch: [25/50] Step: [800/938] G loss: 5.12038  D loss: 0.00537  \n",
            "Train Epoch: [25/50] Step: [900/938] G loss: 5.12239  D loss: 0.00520  \n",
            "Train Epoch: [26/50] Step: [0/938]   G loss: 5.03588  D loss: 0.00648  \n",
            "Train Epoch: [26/50] Step: [100/938] G loss: 4.96296  D loss: 0.00655  \n",
            "Train Epoch: [26/50] Step: [200/938] G loss: 4.84077  D loss: 0.00634  \n",
            "Train Epoch: [26/50] Step: [300/938] G loss: 5.10459  D loss: 0.00979  \n",
            "Train Epoch: [26/50] Step: [400/938] G loss: 5.11044  D loss: 0.01431  \n",
            "Train Epoch: [26/50] Step: [500/938] G loss: 5.21979  D loss: 0.00474  \n",
            "Train Epoch: [26/50] Step: [600/938] G loss: 5.21850  D loss: 0.00459  \n",
            "Train Epoch: [26/50] Step: [700/938] G loss: 5.30776  D loss: 0.00468  \n",
            "Train Epoch: [26/50] Step: [800/938] G loss: 5.04583  D loss: 0.00754  \n",
            "Train Epoch: [26/50] Step: [900/938] G loss: 5.27983  D loss: 0.00430  \n",
            "Train Epoch: [27/50] Step: [0/938]   G loss: 5.06992  D loss: 0.00451  \n",
            "Train Epoch: [27/50] Step: [100/938] G loss: 5.26674  D loss: 0.00664  \n",
            "Train Epoch: [27/50] Step: [200/938] G loss: 5.05230  D loss: 0.00912  \n",
            "Train Epoch: [27/50] Step: [300/938] G loss: 5.17473  D loss: 0.00570  \n",
            "Train Epoch: [27/50] Step: [400/938] G loss: 5.34028  D loss: 0.02189  \n",
            "Train Epoch: [27/50] Step: [500/938] G loss: 5.46112  D loss: 0.00356  \n",
            "Train Epoch: [27/50] Step: [600/938] G loss: 5.36207  D loss: 0.00388  \n",
            "Train Epoch: [27/50] Step: [700/938] G loss: 5.23109  D loss: 0.00400  \n",
            "Train Epoch: [27/50] Step: [800/938] G loss: 5.20179  D loss: 0.00593  \n",
            "Train Epoch: [27/50] Step: [900/938] G loss: 5.37574  D loss: 0.01649  \n",
            "Train Epoch: [28/50] Step: [0/938]   G loss: 5.25638  D loss: 0.00536  \n",
            "Train Epoch: [28/50] Step: [100/938] G loss: 5.13823  D loss: 0.00595  \n",
            "Train Epoch: [28/50] Step: [200/938] G loss: 5.34717  D loss: 0.00492  \n",
            "Train Epoch: [28/50] Step: [300/938] G loss: 5.26492  D loss: 0.00674  \n",
            "Train Epoch: [28/50] Step: [400/938] G loss: 5.07575  D loss: 0.00727  \n",
            "Train Epoch: [28/50] Step: [500/938] G loss: 5.46451  D loss: 0.00408  \n",
            "Train Epoch: [28/50] Step: [600/938] G loss: 5.59650  D loss: 0.00322  \n",
            "Train Epoch: [28/50] Step: [700/938] G loss: 5.31215  D loss: 0.00471  \n",
            "Train Epoch: [28/50] Step: [800/938] G loss: 5.26502  D loss: 0.00455  \n",
            "Train Epoch: [28/50] Step: [900/938] G loss: 5.46600  D loss: 0.00468  \n",
            "Train Epoch: [29/50] Step: [0/938]   G loss: 5.58834  D loss: 0.00518  \n",
            "Train Epoch: [29/50] Step: [100/938] G loss: 5.40065  D loss: 0.00321  \n",
            "Train Epoch: [29/50] Step: [200/938] G loss: 5.39241  D loss: 0.00430  \n",
            "Train Epoch: [29/50] Step: [300/938] G loss: 5.42683  D loss: 0.00448  \n",
            "Train Epoch: [29/50] Step: [400/938] G loss: 5.57020  D loss: 0.00322  \n",
            "Train Epoch: [29/50] Step: [500/938] G loss: 5.51138  D loss: 0.02754  \n",
            "Train Epoch: [29/50] Step: [600/938] G loss: 5.65465  D loss: 0.00375  \n",
            "Train Epoch: [29/50] Step: [700/938] G loss: 5.66855  D loss: 0.00284  \n",
            "Train Epoch: [29/50] Step: [800/938] G loss: 5.75943  D loss: 0.00321  \n",
            "Train Epoch: [29/50] Step: [900/938] G loss: 5.02633  D loss: 0.00480  \n",
            "Train Epoch: [30/50] Step: [0/938]   G loss: 5.69091  D loss: 0.00299  \n",
            "Train Epoch: [30/50] Step: [100/938] G loss: 5.61152  D loss: 0.00353  \n",
            "Train Epoch: [30/50] Step: [200/938] G loss: 5.73899  D loss: 0.00328  \n",
            "Train Epoch: [30/50] Step: [300/938] G loss: 5.58713  D loss: 0.00496  \n",
            "Train Epoch: [30/50] Step: [400/938] G loss: 5.45665  D loss: 0.00491  \n",
            "Train Epoch: [30/50] Step: [500/938] G loss: 5.58266  D loss: 0.00345  \n",
            "Train Epoch: [30/50] Step: [600/938] G loss: 5.72582  D loss: 0.00334  \n",
            "Train Epoch: [30/50] Step: [700/938] G loss: 5.64228  D loss: 0.00532  \n",
            "Train Epoch: [30/50] Step: [800/938] G loss: 5.96682  D loss: 0.00273  \n",
            "Train Epoch: [30/50] Step: [900/938] G loss: 5.80501  D loss: 0.00221  \n",
            "Train Epoch: [31/50] Step: [0/938]   G loss: 5.53577  D loss: 0.00651  \n",
            "Train Epoch: [31/50] Step: [100/938] G loss: 5.79542  D loss: 0.00520  \n",
            "Train Epoch: [31/50] Step: [200/938] G loss: 5.67519  D loss: 0.00362  \n",
            "Train Epoch: [31/50] Step: [300/938] G loss: 5.80460  D loss: 0.00336  \n",
            "Train Epoch: [31/50] Step: [400/938] G loss: 5.42954  D loss: 0.00608  \n",
            "Train Epoch: [31/50] Step: [500/938] G loss: 5.59222  D loss: 0.00368  \n",
            "Train Epoch: [31/50] Step: [600/938] G loss: 5.63066  D loss: 0.00263  \n",
            "Train Epoch: [31/50] Step: [700/938] G loss: 5.73679  D loss: 0.01622  \n",
            "Train Epoch: [31/50] Step: [800/938] G loss: 5.84516  D loss: 0.00429  \n",
            "Train Epoch: [31/50] Step: [900/938] G loss: 5.66444  D loss: 0.01589  \n",
            "Train Epoch: [32/50] Step: [0/938]   G loss: 5.63915  D loss: 0.00316  \n",
            "Train Epoch: [32/50] Step: [100/938] G loss: 5.76261  D loss: 0.00271  \n",
            "Train Epoch: [32/50] Step: [200/938] G loss: 5.73063  D loss: 0.00345  \n",
            "Train Epoch: [32/50] Step: [300/938] G loss: 6.14737  D loss: 0.00312  \n",
            "Train Epoch: [32/50] Step: [400/938] G loss: 5.64674  D loss: 0.00501  \n",
            "Train Epoch: [32/50] Step: [500/938] G loss: 5.80328  D loss: 0.03573  \n",
            "Train Epoch: [32/50] Step: [600/938] G loss: 6.02691  D loss: 0.00212  \n",
            "Train Epoch: [32/50] Step: [700/938] G loss: 6.07655  D loss: 0.00513  \n",
            "Train Epoch: [32/50] Step: [800/938] G loss: 5.99355  D loss: 0.00428  \n",
            "Train Epoch: [32/50] Step: [900/938] G loss: 5.84663  D loss: 0.01956  \n",
            "Train Epoch: [33/50] Step: [0/938]   G loss: 5.68674  D loss: 0.00244  \n",
            "Train Epoch: [33/50] Step: [100/938] G loss: 6.20304  D loss: 0.00363  \n",
            "Train Epoch: [33/50] Step: [200/938] G loss: 5.86582  D loss: 0.00274  \n",
            "Train Epoch: [33/50] Step: [300/938] G loss: 6.18231  D loss: 0.00190  \n",
            "Train Epoch: [33/50] Step: [400/938] G loss: 5.76433  D loss: 0.00296  \n",
            "Train Epoch: [33/50] Step: [500/938] G loss: 6.13335  D loss: 0.00186  \n",
            "Train Epoch: [33/50] Step: [600/938] G loss: 5.73665  D loss: 0.00255  \n",
            "Train Epoch: [33/50] Step: [700/938] G loss: 5.86239  D loss: 0.00352  \n",
            "Train Epoch: [33/50] Step: [800/938] G loss: 5.89058  D loss: 0.00250  \n",
            "Train Epoch: [33/50] Step: [900/938] G loss: 6.10274  D loss: 0.00258  \n",
            "Train Epoch: [34/50] Step: [0/938]   G loss: 6.09101  D loss: 0.00215  \n",
            "Train Epoch: [34/50] Step: [100/938] G loss: 6.25366  D loss: 0.00158  \n",
            "Train Epoch: [34/50] Step: [200/938] G loss: 6.12691  D loss: 0.00213  \n",
            "Train Epoch: [34/50] Step: [300/938] G loss: 5.53669  D loss: 0.00356  \n",
            "Train Epoch: [34/50] Step: [400/938] G loss: 6.15433  D loss: 0.00284  \n",
            "Train Epoch: [34/50] Step: [500/938] G loss: 5.73748  D loss: 0.00225  \n",
            "Train Epoch: [34/50] Step: [600/938] G loss: 6.08913  D loss: 0.00228  \n",
            "Train Epoch: [34/50] Step: [700/938] G loss: 5.99239  D loss: 0.00367  \n",
            "Train Epoch: [34/50] Step: [800/938] G loss: 6.13283  D loss: 0.00240  \n",
            "Train Epoch: [34/50] Step: [900/938] G loss: 6.20643  D loss: 0.00182  \n",
            "Train Epoch: [35/50] Step: [0/938]   G loss: 5.48301  D loss: 0.00344  \n",
            "Train Epoch: [35/50] Step: [100/938] G loss: 6.15884  D loss: 0.00262  \n",
            "Train Epoch: [35/50] Step: [200/938] G loss: 6.11655  D loss: 0.00202  \n",
            "Train Epoch: [35/50] Step: [300/938] G loss: 6.39109  D loss: 0.00212  \n",
            "Train Epoch: [35/50] Step: [400/938] G loss: 5.70483  D loss: 0.00568  \n",
            "Train Epoch: [35/50] Step: [500/938] G loss: 6.10532  D loss: 0.00312  \n",
            "Train Epoch: [35/50] Step: [600/938] G loss: 5.83355  D loss: 0.00230  \n",
            "Train Epoch: [35/50] Step: [700/938] G loss: 6.22614  D loss: 0.00146  \n",
            "Train Epoch: [35/50] Step: [800/938] G loss: 6.23945  D loss: 0.00167  \n",
            "Train Epoch: [35/50] Step: [900/938] G loss: 6.38303  D loss: 0.00212  \n",
            "Train Epoch: [36/50] Step: [0/938]   G loss: 5.80139  D loss: 0.00252  \n",
            "Train Epoch: [36/50] Step: [100/938] G loss: 6.18678  D loss: 0.00482  \n",
            "Train Epoch: [36/50] Step: [200/938] G loss: 6.27487  D loss: 0.00210  \n",
            "Train Epoch: [36/50] Step: [300/938] G loss: 6.17343  D loss: 0.00258  \n",
            "Train Epoch: [36/50] Step: [400/938] G loss: 6.24788  D loss: 0.00179  \n",
            "Train Epoch: [36/50] Step: [500/938] G loss: 6.00089  D loss: 0.00277  \n",
            "Train Epoch: [36/50] Step: [600/938] G loss: 6.14941  D loss: 0.00270  \n",
            "Train Epoch: [36/50] Step: [700/938] G loss: 6.20342  D loss: 0.00172  \n",
            "Train Epoch: [36/50] Step: [800/938] G loss: 6.36790  D loss: 0.00333  \n",
            "Train Epoch: [36/50] Step: [900/938] G loss: 6.34784  D loss: 0.00249  \n",
            "Train Epoch: [37/50] Step: [0/938]   G loss: 5.65541  D loss: 0.00365  \n",
            "Train Epoch: [37/50] Step: [100/938] G loss: 6.34629  D loss: 0.00140  \n",
            "Train Epoch: [37/50] Step: [200/938] G loss: 6.05156  D loss: 0.00201  \n",
            "Train Epoch: [37/50] Step: [300/938] G loss: 6.09128  D loss: 0.00187  \n",
            "Train Epoch: [37/50] Step: [400/938] G loss: 6.54203  D loss: 0.00141  \n",
            "Train Epoch: [37/50] Step: [500/938] G loss: 6.36840  D loss: 0.00133  \n",
            "Train Epoch: [37/50] Step: [600/938] G loss: 6.64188  D loss: 0.00128  \n",
            "Train Epoch: [37/50] Step: [700/938] G loss: 6.45260  D loss: 0.00125  \n",
            "Train Epoch: [37/50] Step: [800/938] G loss: 6.49198  D loss: 0.00120  \n",
            "Train Epoch: [37/50] Step: [900/938] G loss: 6.54103  D loss: 0.00211  \n",
            "Train Epoch: [38/50] Step: [0/938]   G loss: 5.78367  D loss: 0.00306  \n",
            "Train Epoch: [38/50] Step: [100/938] G loss: 6.38733  D loss: 0.00196  \n",
            "Train Epoch: [38/50] Step: [200/938] G loss: 6.46764  D loss: 0.00278  \n",
            "Train Epoch: [38/50] Step: [300/938] G loss: 6.77995  D loss: 0.00304  \n",
            "Train Epoch: [38/50] Step: [400/938] G loss: 6.25407  D loss: 0.00156  \n",
            "Train Epoch: [38/50] Step: [500/938] G loss: 6.58862  D loss: 0.00343  \n",
            "Train Epoch: [38/50] Step: [600/938] G loss: 6.73530  D loss: 0.00107  \n",
            "Train Epoch: [38/50] Step: [700/938] G loss: 6.52440  D loss: 0.00172  \n",
            "Train Epoch: [38/50] Step: [800/938] G loss: 6.82116  D loss: 0.00152  \n",
            "Train Epoch: [38/50] Step: [900/938] G loss: 6.61923  D loss: 0.00252  \n",
            "Train Epoch: [39/50] Step: [0/938]   G loss: 6.57833  D loss: 0.00110  \n",
            "Train Epoch: [39/50] Step: [100/938] G loss: 6.71772  D loss: 0.00406  \n",
            "Train Epoch: [39/50] Step: [200/938] G loss: 6.51740  D loss: 0.00226  \n",
            "Train Epoch: [39/50] Step: [300/938] G loss: 6.63334  D loss: 0.00200  \n",
            "Train Epoch: [39/50] Step: [400/938] G loss: 6.87525  D loss: 0.00079  \n",
            "Train Epoch: [39/50] Step: [500/938] G loss: 6.53067  D loss: 0.00117  \n",
            "Train Epoch: [39/50] Step: [600/938] G loss: 6.32582  D loss: 0.01374  \n",
            "Train Epoch: [39/50] Step: [700/938] G loss: 6.59341  D loss: 0.00412  \n",
            "Train Epoch: [39/50] Step: [800/938] G loss: 6.78879  D loss: 0.00140  \n",
            "Train Epoch: [39/50] Step: [900/938] G loss: 6.29768  D loss: 0.00221  \n",
            "Train Epoch: [40/50] Step: [0/938]   G loss: 6.51172  D loss: 0.00141  \n",
            "Train Epoch: [40/50] Step: [100/938] G loss: 6.30206  D loss: 0.00128  \n",
            "Train Epoch: [40/50] Step: [200/938] G loss: 6.56507  D loss: 0.00176  \n",
            "Train Epoch: [40/50] Step: [300/938] G loss: 6.50836  D loss: 0.00109  \n",
            "Train Epoch: [40/50] Step: [400/938] G loss: 6.62958  D loss: 0.00145  \n",
            "Train Epoch: [40/50] Step: [500/938] G loss: 6.75414  D loss: 0.00201  \n",
            "Train Epoch: [40/50] Step: [600/938] G loss: 6.65544  D loss: 0.00144  \n",
            "Train Epoch: [40/50] Step: [700/938] G loss: 6.79697  D loss: 0.00092  \n",
            "Train Epoch: [40/50] Step: [800/938] G loss: 6.41067  D loss: 0.00182  \n",
            "Train Epoch: [40/50] Step: [900/938] G loss: 6.77140  D loss: 0.00119  \n",
            "Train Epoch: [41/50] Step: [0/938]   G loss: 6.59062  D loss: 0.00233  \n",
            "Train Epoch: [41/50] Step: [100/938] G loss: 6.72403  D loss: 0.00352  \n",
            "Train Epoch: [41/50] Step: [200/938] G loss: 6.92899  D loss: 0.00107  \n",
            "Train Epoch: [41/50] Step: [300/938] G loss: 6.37199  D loss: 0.00131  \n",
            "Train Epoch: [41/50] Step: [400/938] G loss: 6.66346  D loss: 0.00125  \n",
            "Train Epoch: [41/50] Step: [500/938] G loss: 6.74908  D loss: 0.00136  \n",
            "Train Epoch: [41/50] Step: [600/938] G loss: 6.93795  D loss: 0.00169  \n",
            "Train Epoch: [41/50] Step: [700/938] G loss: 7.13083  D loss: 0.00095  \n",
            "Train Epoch: [41/50] Step: [800/938] G loss: 6.47169  D loss: 0.00118  \n",
            "Train Epoch: [41/50] Step: [900/938] G loss: 7.02417  D loss: 0.00102  \n",
            "Train Epoch: [42/50] Step: [0/938]   G loss: 7.09131  D loss: 0.00087  \n",
            "Train Epoch: [42/50] Step: [100/938] G loss: 6.76248  D loss: 0.00138  \n",
            "Train Epoch: [42/50] Step: [200/938] G loss: 6.87427  D loss: 0.00451  \n",
            "Train Epoch: [42/50] Step: [300/938] G loss: 7.11910  D loss: 0.00080  \n",
            "Train Epoch: [42/50] Step: [400/938] G loss: 6.95433  D loss: 0.00100  \n",
            "Train Epoch: [42/50] Step: [500/938] G loss: 7.00274  D loss: 0.00082  \n",
            "Train Epoch: [42/50] Step: [600/938] G loss: 6.95614  D loss: 0.00091  \n",
            "Train Epoch: [42/50] Step: [700/938] G loss: 6.67337  D loss: 0.00181  \n",
            "Train Epoch: [42/50] Step: [800/938] G loss: 6.85136  D loss: 0.00110  \n",
            "Train Epoch: [42/50] Step: [900/938] G loss: 6.54351  D loss: 0.00125  \n",
            "Train Epoch: [43/50] Step: [0/938]   G loss: 6.56059  D loss: 0.00138  \n",
            "Train Epoch: [43/50] Step: [100/938] G loss: 7.16929  D loss: 0.00093  \n",
            "Train Epoch: [43/50] Step: [200/938] G loss: 6.95362  D loss: 0.00100  \n",
            "Train Epoch: [43/50] Step: [300/938] G loss: 6.81549  D loss: 0.00077  \n",
            "Train Epoch: [43/50] Step: [400/938] G loss: 6.71693  D loss: 0.00157  \n",
            "Train Epoch: [43/50] Step: [500/938] G loss: 6.94014  D loss: 0.00123  \n",
            "Train Epoch: [43/50] Step: [600/938] G loss: 6.69076  D loss: 0.00098  \n",
            "Train Epoch: [43/50] Step: [700/938] G loss: 6.89689  D loss: 0.00288  \n",
            "Train Epoch: [43/50] Step: [800/938] G loss: 6.32295  D loss: 0.00111  \n",
            "Train Epoch: [43/50] Step: [900/938] G loss: 6.27144  D loss: 0.00177  \n",
            "Train Epoch: [44/50] Step: [0/938]   G loss: 6.50118  D loss: 0.00175  \n",
            "Train Epoch: [44/50] Step: [100/938] G loss: 6.54916  D loss: 0.00161  \n",
            "Train Epoch: [44/50] Step: [200/938] G loss: 6.58797  D loss: 0.00233  \n",
            "Train Epoch: [44/50] Step: [300/938] G loss: 6.79903  D loss: 0.00114  \n",
            "Train Epoch: [44/50] Step: [400/938] G loss: 6.71158  D loss: 0.01791  \n",
            "Train Epoch: [44/50] Step: [500/938] G loss: 6.57274  D loss: 0.00185  \n",
            "Train Epoch: [44/50] Step: [600/938] G loss: 6.58256  D loss: 0.00129  \n",
            "Train Epoch: [44/50] Step: [700/938] G loss: 6.92087  D loss: 0.00106  \n",
            "Train Epoch: [44/50] Step: [800/938] G loss: 6.52375  D loss: 0.00109  \n",
            "Train Epoch: [44/50] Step: [900/938] G loss: 6.98776  D loss: 0.00130  \n",
            "Train Epoch: [45/50] Step: [0/938]   G loss: 6.97096  D loss: 0.00230  \n",
            "Train Epoch: [45/50] Step: [100/938] G loss: 6.45540  D loss: 0.00148  \n",
            "Train Epoch: [45/50] Step: [200/938] G loss: 6.96006  D loss: 0.00130  \n",
            "Train Epoch: [45/50] Step: [300/938] G loss: 7.19069  D loss: 0.00062  \n",
            "Train Epoch: [45/50] Step: [400/938] G loss: 7.01315  D loss: 0.00116  \n",
            "Train Epoch: [45/50] Step: [500/938] G loss: 7.12980  D loss: 0.00089  \n",
            "Train Epoch: [45/50] Step: [600/938] G loss: 6.59151  D loss: 0.00106  \n",
            "Train Epoch: [45/50] Step: [700/938] G loss: 7.17556  D loss: 0.00060  \n",
            "Train Epoch: [45/50] Step: [800/938] G loss: 7.10177  D loss: 0.00066  \n",
            "Train Epoch: [45/50] Step: [900/938] G loss: 6.74994  D loss: 0.00114  \n",
            "Train Epoch: [46/50] Step: [0/938]   G loss: 7.05359  D loss: 0.00091  \n",
            "Train Epoch: [46/50] Step: [100/938] G loss: 6.91453  D loss: 0.00121  \n",
            "Train Epoch: [46/50] Step: [200/938] G loss: 7.13520  D loss: 0.00060  \n",
            "Train Epoch: [46/50] Step: [300/938] G loss: 7.19289  D loss: 0.00055  \n",
            "Train Epoch: [46/50] Step: [400/938] G loss: 7.31596  D loss: 0.00052  \n",
            "Train Epoch: [46/50] Step: [500/938] G loss: 7.28406  D loss: 0.00091  \n",
            "Train Epoch: [46/50] Step: [600/938] G loss: 6.69003  D loss: 0.00112  \n",
            "Train Epoch: [46/50] Step: [700/938] G loss: 6.79866  D loss: 0.00694  \n",
            "Train Epoch: [46/50] Step: [800/938] G loss: 6.89722  D loss: 0.00102  \n",
            "Train Epoch: [46/50] Step: [900/938] G loss: 6.82107  D loss: 0.00071  \n",
            "Train Epoch: [47/50] Step: [0/938]   G loss: 7.12553  D loss: 0.00080  \n",
            "Train Epoch: [47/50] Step: [100/938] G loss: 7.25321  D loss: 0.00057  \n",
            "Train Epoch: [47/50] Step: [200/938] G loss: 7.06696  D loss: 0.00066  \n",
            "Train Epoch: [47/50] Step: [300/938] G loss: 6.99495  D loss: 0.00072  \n",
            "Train Epoch: [47/50] Step: [400/938] G loss: 7.06653  D loss: 0.00230  \n",
            "Train Epoch: [47/50] Step: [500/938] G loss: 6.93287  D loss: 0.00093  \n",
            "Train Epoch: [47/50] Step: [600/938] G loss: 7.33708  D loss: 0.00053  \n",
            "Train Epoch: [47/50] Step: [700/938] G loss: 7.00809  D loss: 0.00091  \n",
            "Train Epoch: [47/50] Step: [800/938] G loss: 6.95979  D loss: 0.00077  \n",
            "Train Epoch: [47/50] Step: [900/938] G loss: 7.11732  D loss: 0.00065  \n",
            "Train Epoch: [48/50] Step: [0/938]   G loss: 7.08555  D loss: 0.00068  \n",
            "Train Epoch: [48/50] Step: [100/938] G loss: 7.03155  D loss: 0.00102  \n",
            "Train Epoch: [48/50] Step: [200/938] G loss: 7.01787  D loss: 0.00073  \n",
            "Train Epoch: [48/50] Step: [300/938] G loss: 7.44520  D loss: 0.00053  \n",
            "Train Epoch: [48/50] Step: [400/938] G loss: 7.07205  D loss: 0.00086  \n",
            "Train Epoch: [48/50] Step: [500/938] G loss: 7.40866  D loss: 0.00070  \n",
            "Train Epoch: [48/50] Step: [600/938] G loss: 6.34988  D loss: 0.00159  \n",
            "Train Epoch: [48/50] Step: [700/938] G loss: 7.05397  D loss: 0.00080  \n",
            "Train Epoch: [48/50] Step: [800/938] G loss: 7.06727  D loss: 0.00083  \n",
            "Train Epoch: [48/50] Step: [900/938] G loss: 7.20777  D loss: 0.00063  \n",
            "Train Epoch: [49/50] Step: [0/938]   G loss: 7.21891  D loss: 0.00060  \n",
            "Train Epoch: [49/50] Step: [100/938] G loss: 7.01993  D loss: 0.00068  \n",
            "Train Epoch: [49/50] Step: [200/938] G loss: 7.25675  D loss: 0.00073  \n",
            "Train Epoch: [49/50] Step: [300/938] G loss: 6.92573  D loss: 0.00190  \n",
            "Train Epoch: [49/50] Step: [400/938] G loss: 7.28637  D loss: 0.00062  \n",
            "Train Epoch: [49/50] Step: [500/938] G loss: 7.25442  D loss: 0.00054  \n",
            "Train Epoch: [49/50] Step: [600/938] G loss: 7.12027  D loss: 0.00081  \n",
            "Train Epoch: [49/50] Step: [700/938] G loss: 6.95940  D loss: 0.00163  \n",
            "Train Epoch: [49/50] Step: [800/938] G loss: 7.29860  D loss: 0.00051  \n",
            "Train Epoch: [49/50] Step: [900/938] G loss: 7.48008  D loss: 0.00083  \n"
          ]
        }
      ],
      "source": [
        "discriminator.train()\n",
        "\n",
        "g_loss = torch.Tensor([0])\n",
        "d_loss = torch.Tensor([0])\n",
        "\n",
        "for epoch in range(parser.n_epochs):\n",
        "  for batch_idx, (x, y) in enumerate(train_loader):\n",
        "    # 이미지의 28 * 28 차원을 784 하나의 차원으로 바꾼다.\n",
        "    x_flatten = x.view(x.shape[0], -1)\n",
        "\n",
        "    # 레이블에 관하여 one-hot encoding\n",
        "    one_hot_label = torch.nn.functional.one_hot(y, num_classes=parser['n_classes'])\n",
        "\n",
        "    # GPU로 올리기\n",
        "    img_torch2vec = x_flatten.type(torch.FloatTensor).cuda()\n",
        "    label_torch = one_hot_label.type(torch.FloatTensor).cuda()\n",
        "\n",
        "    valid = torch.ones(parser.batch_size, 1).cuda()\n",
        "    fake = torch.zeros(parser.batch_size, 1).cuda()\n",
        "\n",
        "    real_imgs = img_torch2vec\n",
        "    labels = label_torch\n",
        "\n",
        "    # Train generator\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    z = torch.randn(parser.batch_size, parser.latent_dim).cuda()\n",
        "\n",
        "    gen_labels = []\n",
        "\n",
        "    # noise에 관해 임의로 label 생성\n",
        "    for randpos in np.random.randint(0, parser.n_classes, parser.batch_size):\n",
        "      gen_labels.append(torch.eye(parser.n_classes)[randpos])\n",
        "\n",
        "    # shape of gen_labels: (n_row, 10)\n",
        "    gen_labels = torch.stack(gen_labels).cuda()\n",
        "\n",
        "    gen_imgs = generator(z, gen_labels)\n",
        "\n",
        "    val_output = discriminator(gen_imgs, gen_labels)\n",
        "    g_loss = cross_entropy(val_output, valid)\n",
        "\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "\n",
        "    # Train discriminator\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    validity_real = discriminator(real_imgs, labels)\n",
        "\n",
        "    # batch의 크기가 설정한 batch 크기보다 모자란 경우 (마지막 배치 가능성)\n",
        "    try:\n",
        "      d_real_loss = cross_entropy(validity_real, valid)\n",
        "    except:\n",
        "      valid = torch.ones(validity_real.shape[0], 1).cuda()\n",
        "      d_real_loss = cross_entropy(validity_real, valid)\n",
        "\n",
        "    validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
        "    d_fake_loss = cross_entropy(validity_fake, fake)\n",
        "\n",
        "    d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "       print('{:<13s}{:<8s}{:<6s}{:<10s}{:<8s}{:<9.5f}{:<8s}{:<9.5f}'\n",
        "       .format('Train Epoch: ', '[' + str(epoch) + '/' + str(parser['n_epochs']) + ']', \n",
        "               'Step: ', '[' + str(batch_idx) + '/' + str(len(train_loader)) + ']', \n",
        "               'G loss: ', g_loss.item(), \n",
        "               'D loss: ', d_loss.item())\n",
        "       )\n",
        "\n",
        "    \n",
        "  if epoch % parser.sample_interval == 0:\n",
        "    sample_image(n_row=10, epoch=epoch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "😓 I think a mode collapse might have occured..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4mOIEGF23J9m"
      },
      "outputs": [],
      "source": [
        "def show_image(condition:int):\n",
        "  generator.eval()\n",
        "\n",
        "  z = torch.randn(1, parser.latent_dim).type(torch.FloatTensor).cuda()\n",
        "  condition_vector = torch.eye(parser.n_calsses)[condition].reshape(-1, 1).cuda()\n",
        "  gen_imgs = generator(z, condition_vector)\n",
        "  plt.imshow(gen_imgs.view(1, 1, 28, 28)[0][0].detach().cpu().numpy(), cmap='gray')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
